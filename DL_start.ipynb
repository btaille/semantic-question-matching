{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from embeddings import load_embeddings, word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameters = OrderedDict()\n",
    "\n",
    "parameters[\"embeds\"] = \"glove\"\n",
    "parameters[\"w_embed_size\"] = 300\n",
    "parameters[\"load_embeds\"] = True\n",
    "parameters[\"freeze\"] = True\n",
    "parameters[\"batch_size\"] = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from saved word_embeddings\n",
      "Loading vocab\n"
     ]
    }
   ],
   "source": [
    "if parameters[\"embeds\"] == \"glove\":\n",
    "    embeddings_path = \"word_embeddings/glove.6B/glove.6B.%sd_w2vformat.txt\" % parameters[\"w_embed_size\"]\n",
    "    binary = False\n",
    "else:\n",
    "    embeddings_path = \"word_embeddings/google/GoogleNews-vectors-negative300.bin\"\n",
    "    binary = True\n",
    "    \n",
    "if parameters[\"load_embeds\"]:\n",
    "    loaded_embeddings, (w2idx, idx2w) = load_embeddings(embeddings_path, binary=binary)\n",
    "else:\n",
    "    parameters[\"freeze\"] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Quora question pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"data/quora/\"\n",
    "\n",
    "# Download train/test from https://www.kaggle.com/c/quora-question-pairs/data\n",
    "df_train = pd.read_csv(data_path + \"train.csv\")\n",
    "df_test = pd.read_csv(data_path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "q_dict = {}\n",
    "\n",
    "qid1 = np.array(df_train[\"qid1\"])\n",
    "qid2 = np.array(df_train[\"qid2\"])\n",
    "\n",
    "q1 = np.array(df_train[\"question1\"])\n",
    "q2 = np.array(df_train[\"question2\"])\n",
    "is_duplicate = np.array(df_train[\"is_duplicate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i,qid in enumerate(qid1):\n",
    "    if qid not in q_dict:\n",
    "        q_dict[qid] = q1[i]\n",
    "        \n",
    "for i,qid in enumerate(qid2):\n",
    "    if qid not in q_dict:\n",
    "        q_dict[qid] = q2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where can I watch sarrainodu with subtitles?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dict[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174364 nan\n"
     ]
    }
   ],
   "source": [
    "for k,v in q_dict.items():\n",
    "    if not type(v) == str:\n",
    "        print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>105780</th>\n",
       "      <td>105780</td>\n",
       "      <td>174363</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I develop android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201841</th>\n",
       "      <td>201841</td>\n",
       "      <td>303951</td>\n",
       "      <td>174364</td>\n",
       "      <td>How can I create an Android app?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id    qid1    qid2                         question1 question2  \\\n",
       "105780  105780  174363  174364    How can I develop android app?       NaN   \n",
       "201841  201841  303951  174364  How can I create an Android app?       NaN   \n",
       "\n",
       "        is_duplicate  \n",
       "105780             0  \n",
       "201841             0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_dict[174364] = \"nan\"\n",
    "df_train[df_train[\"qid2\"]==174364]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lower_list(l):\n",
    "    return([elt.lower() for elt in l])\n",
    "\n",
    "\n",
    "def tokenize(sents, lower=True, stemmer=None):\n",
    "    if stemmer == \"english\":\n",
    "        snowball = SnowballStemmer(\"english\")\n",
    "        return [lower_list([snowball.stem(token) for token in word_tokenize(sent)]) if lower \n",
    "                else  [snowball.stem(token) for token in word_tokenize(sent)] \n",
    "                for sent in sents]\n",
    "    else:\n",
    "        return [lower_list(word_tokenize(sent)) if lower\n",
    "                else word_tokenize(sent)\n",
    "                for sent in sents]\n",
    "    \n",
    "    \n",
    "def tokenize_dict(q_dict, lower=True, stemmer=None):\n",
    "    if stemmer == \"english\":\n",
    "        snowball = SnowballStemmer(\"english\")\n",
    "        return {k:lower_list([snowball.stem(token) for token in word_tokenize(q_dict[k])]) if lower\n",
    "                else [snowball.stem(token) for token in word_tokenize(q_dict[k])]\n",
    "                for k in q_dict.keys()}\n",
    "    else:\n",
    "        return {k:lower_list(word_tokenize(q_dict[k])) if lower\n",
    "                else word_tokenize(q_dict[k])\n",
    "                for k in q_dict.keys()}\n",
    "    \n",
    "def sent2ids(sent, w2idx):\n",
    "    return [w2idx[w] for w in sent]\n",
    "\n",
    "def ids2sent(ids, idx2w):\n",
    "    return [idx2w[i] for i in ids]\n",
    "\n",
    "def pad_sequence(ids, pad_tok, maxlen):\n",
    "    return ids[:maxlen] + [pad_tok] * max(maxlen - len(ids), 0)\n",
    "\n",
    "def sequence_dict(tok_dict, w2idx):    \n",
    "    seq_dict = {k:sent2ids(tok_dict[k], w2idx) for k in tok_dict.keys()}    \n",
    "    return seq_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized = tokenize_dict(q_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113351\n"
     ]
    }
   ],
   "source": [
    "w2idx_train, idx2w_train = word_index(tokenized.values())\n",
    "print(len(w2idx_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['where', 'can', 'i', 'watch', 'sarrainodu', 'with', 'subtitles', '?']\n",
      "[385, 22, 23, 587, 22436, 136, 589, 13]\n",
      "['where', 'can', 'i', 'watch', 'sarrainodu', 'with', 'subtitles', '?']\n"
     ]
    }
   ],
   "source": [
    "s = tokenized[222]\n",
    "\n",
    "ids = sent2ids(s, w2idx_train)\n",
    "s2 = ids2sent(ids, idx2w_train)\n",
    "\n",
    "print(s)\n",
    "print(ids)\n",
    "print(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequences = sequence_dict(tokenized, w2idx_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lens = [len(s) for s in sequences.values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA44AAAJcCAYAAAC2dvoEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1901477438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.hist(lens, max(lens))\n",
    "plt.xlabel('Question length')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Length distribution in train')\n",
    "plt.xlim(1, 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit embeddings to vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 300)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = np.random.normal(scale=0.001, size=(len(w2idx_train), parameters[\"w_embed_size\"]))\n",
    "\n",
    "if parameters[\"load_embeds\"]:\n",
    "    for w, i in w2idx_train.items():\n",
    "        idx = w2idx.get(w)\n",
    "        if idx is not None:\n",
    "            embeddings[i] = loaded_embeddings[idx][:parameters[\"w_embed_size\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00114735,  0.00073054, -0.0019982 , ...,  0.00081816,\n",
       "         0.00155539, -0.00102841],\n",
       "       [-0.20017   ,  0.14302   ,  0.052055  , ...,  0.034939  ,\n",
       "        -0.12599   ,  0.21863   ],\n",
       "       [-0.1749    ,  0.22956   ,  0.24924   , ..., -0.24131   ,\n",
       "        -0.40402001,  0.054744  ],\n",
       "       ..., \n",
       "       [-0.020654  ,  0.051946  , -0.19756   , ..., -0.1902    ,\n",
       "         0.27513999,  0.45159   ],\n",
       "       [ 0.31079   ,  0.57249999,  0.10701   , ...,  0.14535999,\n",
       "         0.57359999,  0.59401   ],\n",
       "       [-0.43546   , -0.14072999, -0.26552999, ...,  0.42638001,\n",
       "        -0.03747   ,  0.26030001]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "hidden_size = 1024\n",
    "drop = 0\n",
    "padlen = 40\n",
    "learn = 0.01\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Placeholders\n",
    "q1 = tf.placeholder(tf.int64, shape=[None, padlen], name=\"question1\")\n",
    "len1 = tf.placeholder(tf.int64, shape=[None], name=\"len1\")\n",
    "\n",
    "q2 = tf.placeholder(tf.int64, shape=[None, padlen], name=\"question2\")\n",
    "len2 = tf.placeholder(tf.int64, shape=[None], name=\"len2\")\n",
    "\n",
    "y = tf.placeholder(tf.int64, shape=[None,2], name=\"is_duplicate\")\n",
    "\n",
    "dropout = tf.placeholder(dtype=tf.float32, shape=[], name=\"dropout\")\n",
    "lr = tf.placeholder(dtype=tf.float32, shape=[], name=\"lr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bilstm(seq, seq_len):\n",
    "    cell_fw = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "    cell_bw = tf.nn.rnn_cell.LSTMCell(hidden_size)\n",
    "    (output_fw, output_bw), _ = tf.nn.bidirectional_dynamic_rnn(cell_fw, cell_bw, seq,\n",
    "                                                                sequence_length=seq_len, \n",
    "                                                                dtype=tf.float32)\n",
    "    output = tf.concat([output_fw, output_bw], axis=-1)\n",
    "    return output\n",
    "\n",
    "\n",
    "def fc(x, W, b):\n",
    "    return tf.matmul(x, W)+ b\n",
    "\n",
    "def activation(x):\n",
    "    return tf.nn.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Embedding layer\n",
    "with tf.variable_scope(\"word_embeddings\") as scope:\n",
    "    _word_embeddings = tf.Variable(embeddings, name=\"_word_embeddings\", dtype=tf.float32, \n",
    "                        trainable=1-parameters[\"freeze\"])\n",
    "    we1 = tf.nn.embedding_lookup(_word_embeddings, q1, name=\"q1_embedded\")\n",
    "    we2 = tf.nn.embedding_lookup(_word_embeddings, q2, name=\"q2_embedded\")\n",
    "\n",
    "    we1 = tf.nn.dropout(we1, dropout)\n",
    "    we2 = tf.nn.dropout(we2, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Shared layer\n",
    "with tf.variable_scope(\"bilstm\") as scope:\n",
    "    lstm1 = bilstm(we1, len1)\n",
    "    scope.reuse_variables()    \n",
    "    lstm2 = bilstm(we2,len2)\n",
    "        \n",
    "max_pool = tf.contrib.keras.layers.GlobalMaxPool1D()\n",
    "        \n",
    "### Max pooling !!!\n",
    "lstm1_pool = max_pool(lstm1)\n",
    "lstm2_pool = max_pool(lstm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Features\n",
    "flat1 = tf.contrib.layers.flatten(lstm1_pool)\n",
    "flat2 = tf.contrib.layers.flatten(lstm2_pool)\n",
    "mult = tf.multiply(flat1, flat2)\n",
    "diff = tf.abs(tf.subtract(flat1, flat2))    \n",
    "concat = tf.concat([flat1, flat2, mult, diff], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### FC layers\n",
    "intermediary_size = 2 + (8*hidden_size - 2) // 2\n",
    "\n",
    "with tf.variable_scope(\"fc1\") as scope:\n",
    "    W = tf.Variable(tf.random_normal([8*hidden_size, intermediary_size]), name=\"w_fc\")\n",
    "    b = tf.Variable(tf.zeros([intermediary_size]), name=\"b_fc\")    \n",
    "    \n",
    "    preact = tf.matmul(concat, W) + b\n",
    "    fc = activation(preact)    \n",
    "    \n",
    "#     tf.summary.histogram(\"weights\", W)\n",
    "    \n",
    "with tf.variable_scope(\"fc2\") as scope:\n",
    "    W = tf.Variable(tf.random_normal([intermediary_size, 2]), name=\"w_fc\")\n",
    "    b = tf.Variable(tf.zeros([2]), name=\"b_fc\")    \n",
    "    \n",
    "    preact = tf.matmul(fc, W) + b\n",
    "    fc = activation(preact)    \n",
    "    \n",
    "#     tf.summary.histogram(\"weights\", W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Loss & optimizer\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=fc))\n",
    "\n",
    "# train_step = tf.train.GradientDescentOptimizer(lr).minimize(cross_entropy)\n",
    "train_step = tf.train.AdamOptimizer(lr).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(fc,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Train_batch_iterator:\n",
    "    def __init__(self, q1ids, q2ids, sequence_dict, is_duplicate, batch_size, padlen=40):\n",
    "        self.i = 0\n",
    "        self.max = len(q1ids)\n",
    "        \n",
    "        self.q1ids = q1ids\n",
    "        self.q2ids = q2ids\n",
    "        self.sequence_dict = sequence_dict\n",
    "        self.is_duplicate = is_duplicate\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.i + self.batch_size < self.max:\n",
    "            q1 = np.array([pad_sequence(self.sequence_dict[qid1[k]], 0, padlen) \n",
    "                           for k in range(self.i, min(self.i + self.batch_size, self.max))])\n",
    "            len1 = [min(len(self.sequence_dict[qid2[k]]), padlen) for k in range(self.i, min(self.i + self.batch_size, self.max))]\n",
    "            \n",
    "            q2 = np.array([pad_sequence(self.sequence_dict[qid1[k]], 0, padlen)\n",
    "                           for k in range(self.i, min(self.i + self.batch_size, self.max))])\n",
    "            len2 = [min(len(self.sequence_dict[qid2[k]]), padlen) for k in range(self.i, min(self.i + self.batch_size, self.max))]\n",
    "            \n",
    "            y = np.concatenate([np.expand_dims(1-is_duplicate[self.i: self.i + self.batch_size], axis=1), \n",
    "                                np.expand_dims(is_duplicate[self.i: self.i + self.batch_size], axis=1)], axis=-1)\n",
    "            \n",
    "            self.i += self.batch_size\n",
    "            return q1, q2, len1, len2, y\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('summaries'):\n",
    "    ce_summary = tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "    acc_summary = tf.summary.scalar('train_batch_accuracy', accuracy)\n",
    "    \n",
    "    summary_op = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter('tensorboard_logs/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter('tensorboard_logs/test', sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50536\n"
     ]
    }
   ],
   "source": [
    "print(len(qid1)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 step 0/50536  acc: 0.25\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-a76972e65cad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqid1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0msave_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"saved/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/Apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state)\u001b[0m\n\u001b[1;32m   1472\u001b[0m         model_checkpoint_path = sess.run(\n\u001b[1;32m   1473\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1474\u001b[0;31m             {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1475\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwrite_state\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/Apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/Apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/Apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/Apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bruno/Apps/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "batch_iter = Train_batch_iterator(qid1, qid2, sequences, is_duplicate, batch_size, padlen)\n",
    "\n",
    "### Test\n",
    "x1, x2, l1, l2, is_dup = batch_iter.__next__()\n",
    "fd_test = {q1: x1, q2: x2, len1: l1, len2: l2, y: is_dup, dropout: 0, lr: learn}\n",
    "\n",
    "\n",
    "### Training\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    for i, (x1, x2, l1, l2, is_dup) in enumerate(batch_iter):\n",
    "        fd_train = {q1: x1, q2: x2, len1: l1, len2: l2, y: is_dup, dropout: drop, lr: learn}\n",
    "        summary, _ = sess.run([summary_op, train_step], feed_dict=fd_train)\n",
    "        train_writer.add_summary(summary, i+(epoch-1)*len(qid1))\n",
    "        save_path = saver.save(sess, \"saved/model.ckpt\")\n",
    "        \n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            summary, acc = sess.run([summary_op, accuracy], feed_dict=fd_test)\n",
    "            print(\"Epoch {}/{} step {}/{}  acc: {}\".format(epoch, epochs, i,len(qid1)//batch_size, acc))\n",
    "            test_writer.add_summary(summary, i+(epoch-1)*len(qid1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}